{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLDS\n",
    "* data is found in data/\n",
    "* weights are saved in weights/\n",
    "* csv are saved in results/\n",
    "* confusion matrices are saved in results/\n",
    "## Files to make before running this notebook:\n",
    "* 10 train csvs for each fold (train_{k}.csv)\n",
    "* 10 val csvs for each fold (val_{k}.csv)\n",
    "* 10 test csvs for each fold (test_{k}.csv)\n",
    "* 10 test csvs with labels for each fold (test_id_labels_{k}.csv)\n",
    "* 1 csv which contains all paths and labels (all_data.csv)\n",
    "  \n",
    "Note: Each fold should be balanced wrt. label and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append(os.path.abspath('../preprocessing'))\n",
    "sys.path.append(os.path.abspath('../helpfunctions'))\n",
    "sys.path.append(os.path.abspath('../models'))\n",
    "from CustomDatasets import CustomDataset1, CustomDataset2\n",
    "from splitpadsave import splitpad\n",
    "from wav2vecClassefier_jonatasgrosman import wav2vecClassefier_jonatasgrosman\n",
    "from Wav2Vec2Classifier_librispeech import Wav2Vec2Classifier_librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the weights are to be saved\n",
    "weight_folder = 'weights/pcgita1_kfolds_64conv_8batch_librispeech'\n",
    "if not os.path.exists(weight_folder): os.makedirs(weight_folder)\n",
    "# where the results (csvs and confusion matrices) are to be saved\n",
    "results_folder = 'results/pcgita1_kfolds_64conv_8batch_librispeech'\n",
    "if not os.path.exists(results_folder): os.makedirs(results_folder)\n",
    "# a csv with all data (id, path to recording, label)\n",
    "data = 'pcgita1_kfolds/all_data.csv'\n",
    "\n",
    "for k in range(2, 11):\n",
    "    print(f'K-fold {k} / 10')\n",
    "    torch.cuda.empty_cache()\n",
    "    # Get IDs\n",
    "    train = f'pcgita1_kfolds/train_{k}.csv'\n",
    "    val = f'pcgita1_kfolds/val_{k}.csv'\n",
    "    test = f'pcgita1_kfolds/test_{k}.csv'\n",
    "    test_id_labels = f'pcgita1_kfolds/test_id_labels_{k}.csv'\n",
    "    # Create data\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, n_test = splitpad(csv_path=data, TRAIN_ID=train, VAL_ID=val, TEST_ID=test, padding_type='reflect', augment=0, length=10, save='no')\n",
    "    # Handling dataset\n",
    "    train = CustomDataset1(X=X_train, y=y_train)\n",
    "    val = CustomDataset1(X=X_val, y=y_val)\n",
    "    test = CustomDataset2(X=X_test, y=y_test, n=n_test)\n",
    "    # Load data with DataLoader\n",
    "    trainloader = DataLoader(train, batch_size=8, drop_last=True, num_workers=0, shuffle=True)\n",
    "    valloader = DataLoader(val, batch_size=8, drop_last=True, num_workers=0, shuffle=False)\n",
    "    testloader = DataLoader(test, batch_size=8, drop_last=True, num_workers=0, shuffle=True)\n",
    "    # Define model\n",
    "    model = Wav2Vec2Classifier_librispeech()\n",
    "    # Train\n",
    "    print('Start training')\n",
    "    model.fit(k=k, train_dataloader=trainloader, val_dataloader=valloader, max_epochs=15, lr=0.0001, weights_folder=weight_folder, results_folder=results_folder)\n",
    "    # Test\n",
    "    print('Start testing')\n",
    "    model.test(test_dataloader=testloader, weights_folder=weight_folder, test_id=test_id_labels, k=k, max_epochs=15, results_folder=results_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
